# ğŸ§  AI-Powered Infrastructure Intelligence System

This repository presents an AI-enhanced platform focused on the intelligent optimization, monitoring, and forensic analysis of data center infrastructure using Large Language Models (LLMs), Reinforcement Learning (RL), and modular DevOps pipelines.

It is built with production-grade architecture, featuring NLP integration via OpenAI APIs (GPT-4), customizable prompt engineering, and full compatibility with MLOps pipelines, CI/CD workflows, and NVIDIA RL technologies.

---

## ğŸš€ Overview

- ğŸ’¡ Developed with advanced **LLM prototyping principles**
- ğŸ§  Supports OpenAIâ€™s **GPT-4 / GPT-3.5-turbo** models
- ğŸ§ª Built for **testable**, **scalable**, and **secure** deployments
- ğŸ” Compatible with **CI/CD**, **containerization**, and **RL** feedback loops
- ğŸ§Š Integrates easily with **NVIDIA AI Enterprise** and **Reinforcement Learning workflows**

---

## âœ¨ Key Features

### âœ… LLM & GenAI Capabilities

- Utilizes OpenAIâ€™s `ChatCompletion` API for AI-based reasoning, analysis, and anomaly detection
- Built-in prompt engineering, rate-limit handling, and structured logging
- Easily extendable to:
  - Retrieval-augmented generation (RAG)
  - Chain-of-thought planning
  - Multimodal prompt ingestion

### ğŸ› ï¸ MLOps-Ready Architecture

- ğŸ³ Containerized with Docker
- ğŸ” CI/CD integration with GitHub Actions
- Configurable deployment across dev, test, and production stages
- Fully supports modular JSON I/O pipelines, logging, and recovery mechanisms

### ğŸ”¬ RL & NVIDIA Compatibility

- Architecture supports integration with:
  - NVIDIA **Triton Inference Server**
  - **RLHF feedback** modeling
  - Custom **reward signal processing**
- Future-ready for **fine-tuning**, **RL control loops**, or **digital twin feedback**

---

## ğŸ§© Tech Stack

| Layer              | Technology                          |
|-------------------|--------------------------------------|
| Language Model     | OpenAI GPT-4 (ChatCompletion API)   |
| Backend Scripts    | Python 3.9+                          |
| Web UI             | Streamlit                           |
| Containers         | Docker                              |
| CI/CD              | GitHub Actions                      |
| RL Readiness       | NVIDIA AI Stack (RLHF / Triton)     |

---

## ğŸ›¡ï¸ Security & Reliability

- âœ… Secure API key handling (.env / dotenv)
- âœ… Exponential backoff for API rate limits
- âœ… Subprocess sandboxing for GUI triggers
- âœ… Full audit trail of AI-generated logs
- âœ… Output validation and formatting enforcement

---

## ğŸ“ˆ Project Structure



---

## ğŸ“Š Use Cases

- ğŸ“¡ Server fleet monitoring and predictive scaling
- ğŸ” AI-based forensic incident investigation (e.g., suspicious failure chains)
- ğŸ§  Adaptive infrastructure control using LLM logic
- ğŸ“‰ Real-time anomaly detection via hybrid ML/statistical inference
- ğŸ’¸ Cost-aware infrastructure decisions (power, cooling, latency optimization)

---

## ğŸ–¥ï¸ Run Locally

### ğŸ”§ Prerequisites

- Python 3.9+
- OpenAI API key (`export OPENAI_API_KEY=your-key`)
- `pip install -r requirements.txt`
- Docker (optional for full isolation)

### â–¶ï¸ Start the Streamlit GUI

```bash
streamlit run app.py

## ğŸš€ Features Walkthrough

Hereâ€™s a visual overview of how the AI-Powered DCIM Server Fleet Optimizer works from GUI to decision logic.

---

### ğŸ§­ 1. Main Dashboard â€” Streamlit GUI
![Main GUI](https://github.com/promiseenofe/Optimal-AIQ--An-AI-Driven-Server-Fleet-Optimization/raw/main/screenshots/generateSS.png)


A clean and intuitive web interface built with **Streamlit**. From here, you can:
- Generate new dynamic server/environment/network/failure data
- Run optimization logic (buy/hold/sell decisions)
- Launch deeper historical analysis
- Trigger visualization modules
Within you can see i generated the dynamic data

---

### ğŸ” 2. Server Fleet Optimization Output
![Server Actions](screenshots/runOptimizeSS.png)

This module analyzes real-time performance metrics like:
- Server failure rate
- Latency
- Energy cost
- Thermal temperature

ğŸ§  Applies **buy/hold/sell** logic using cooldown & fatigue tracking to prevent premature decisions.

---
### ğŸ” 3. Deeper AI-based Failure Trend Analysis
![Deeper Analysis](screenshots/deepFailInvestSS.png)

A CLI-style investigation script that parses:
- AI analysis text for failed vs operational servers
- Tracks server-specific failure frequency
- Summarizes environment/network-related anomalies
- Parses failure + environment + network logs
- Returns structured failure analysis & recommendations
- Enhances traditional rule-based alerts with **LLM intelligence**

---

### ğŸ“Š 4. Visualized Server Actions Over Time
![Chart](screenshots/chartVisuals.png)

Interactive **Matplotlib** or **Altair** chart showing:
- Buy/Hold/Sell trends over historical timestamps
- Identifies recurring decision patterns
- Helps spot action volatility and fatigue misfires

---

---

### ğŸ“ 6. Data & Logs Management
- JSON-based input/output system
- Historical runs saved in `/output/historical_results.json`
- Simplified logs for actions: `/output/server_actions.json`

Each run is **timestamped**, reproducible, and easily parsed for forensics or regression checks.

---

## ğŸ¯ Why These Features Matter

These features work together to:
- Empower decision-making with explainable AI
- Track infrastructure fatigue and avoid overbuying
- Offer **real-time insights** into server performance
- Help IT/DevOps/Data Center teams make cost-aware, fault-resilient decisions
- Maintain forensic-grade evidence for compliance or security review

---

